{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise consists of 4 parts. Finish the first part to get the mark of 3.0. The first 3 parts to get 4.0. Finish all parts to get 5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1) Let us start with a linear regression problem. Consider a linear function with a noise: $y = a*x+b + noise$.\n",
    "\n",
    "We use this formula to generate $100$ random smaples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The number of samples\n",
    "n = 100 \n",
    "### parameters of the linear function\n",
    "a = -2 \n",
    "b = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Now, let us generate 100 samples and plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdf8414d390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### generate equally spaced x-values\n",
    "x = np.linspace(-1, 1, n) \n",
    "### generate y-values (we use a numpy library so we can generate a vector of numbers - y - inline)\n",
    "y = a * x + b + np.random.normal(scale=0.25, size=n)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3) As you may see, the samples are placed - more or less - along a single line.\n",
    "Now, our aim is to find the best parameters for a linear function \n",
    "so that such defined model describes the given data in the best possible way. For this reason, we will iteratively search the parameter space and update the model. Firstly, we need to define an error function. This function will inform how well (or bad) the instantiated model describes the data. For this reason, we use a mean square error function. <br>\n",
    "\n",
    "We define a mean square error function as:<br>\n",
    "$\\dfrac{\\sum\\left(y_i - \\widehat{y}_i \\right)^2}{n} = MSE,$\n",
    "\n",
    "where $y$ are the target (i.e., data values) and $\\widehat{y}$ are the output (i.e., model's) values. <br>\n",
    "\n",
    "See the MSE (mean square error) function given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    return ((y_target - y_calc) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Run the below code for different parameters of the model. Which paramter values give the best (i.e., minimal) MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE  =  0.05607187206995233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdf754aa4d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_2 = -2\n",
    "b_2 = 3\n",
    "\n",
    "y_calc = a_2 * x + b_2\n",
    "print(\"MSE  =  \" + str(mse(y, y_calc)))\n",
    "\n",
    "plt.scatter(x, y, label=\"target\")\n",
    "plt.scatter(x, y_calc, label=\"calculated\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) We want to find the best possible model parameters automatically. For this reason, we use a gradient of a loss function. The gradient informs what is the direction of the fastest increase/decrease of a given function. We use this information to update both model parameters. This procedure will be performed iterativelly. In each iteration, the parameters a and b will be slightly modififed such that MSE will be reduced (i.e., improved). <br>\n",
    "\n",
    "Firstly, finish the below function. It should calculate a gradient of a loss function. Specifically, compute dE/dy (see the Exercies.pdf). (y_target, and y_calc are tensors,  not just scalars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse_grad(y_target, y_calc):\n",
    "    ### TODO\n",
    "    ### return 0\n",
    "\n",
    "### TEST\n",
    "print(mse_grad(y, y_calc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4) Complete the below class representing a linear layer (or just a single linear neuron with one weight \"a\" for the input and one wieght \"b\" for the bias). The update function should alter the weights a and b using the gradient descent algorithm: x is an input vector, grad_y is a gradient of a loss function, i.e., dE/dE, computed using mse_grad method, and lr is the learning rate parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.a * x + self.b\n",
    "\n",
    "    def update(self, x, grad_y, lr):\n",
    "        ### TODO\n",
    "        #self.a = self.a\n",
    "        #self.b = self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5) Complete the below \"step\" function. It shoul (1) compute the y_calc vector, i.e., the output vector, (2) loss, i.e., MSE, (3) gradient of the loss function, i.e., dE/dy, and (4) update the model parameters using the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Step(x, y_target, model, lr):\n",
    "    # TODO\n",
    "    y_calc = 0\n",
    "    loss = 0\n",
    "    #grad_y = \n",
    "    # model.update\n",
    "    return y_calc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6) Instantiate the model. Run the step function for 100 epochs with lr = 0.05, a = 1.1, and b=2. Store the attained losses and plot them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "losses = []\n",
    "for i in range(epoch):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7) You may animate the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "#from matplotlib.animation import FuncAnimation\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearLayer(1.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(x, y)\n",
    "line, = plt.plot(x, y_calc, \".\", c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    y_calc, loss = Step(x, y, model, lr)\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, epoch), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8) The above example can be implemented in pytorch. Read & analyze the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert numpy array to a torch tensor, [:,None] adds an additional dimension\n",
    "xt = torch.FloatTensor(x[:, None])\n",
    "yt = torch.FloatTensor(y[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y_target, y_calc):\n",
    "    return ((y_target - y_calc) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        super(LinearLayer, self).__init__()  # initialize torch functionality\n",
    "        # change a and b to float tensors, and next to parameters,\n",
    "        # the main difference between tensor and parameter is that parameter keeps information about calculations,\n",
    "        # which is used to calculate gradients\n",
    "        self.a = nn.Parameter(torch.FloatTensor([a]).view(1, 1))\n",
    "        self.b = nn.Parameter(torch.FloatTensor([b]))\n",
    "\n",
    "    # forward function is similar to python __call__ but also contains torch functionality\n",
    "    def forward(self, x):\n",
    "        return  x @ self.a + self.b  # linear equation, @ means matrix multiplication for a tensor\n",
    "\n",
    "    def update(self, lr):\n",
    "        with torch.no_grad():  # when we update some parameter, we have to switch off gradient tracking\n",
    "            self.a.sub_(lr * self.a.grad)  # inplace update of parameter a\n",
    "            self.a.grad.zero_()  # clear gradient\n",
    "\n",
    "            self.b.sub_(lr * self.b.grad)\n",
    "            self.b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model =  LinearLayer(1.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def torchStep(x, y, model, lr):\n",
    "    y_calc = model(x)  # calculate the output of our model\n",
    "    loss = mse(y, y_calc)  # calculate the loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    model.update(lr)  # update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep(xt, yt, model, lr)\n",
    "    y_calc = y_calc.detach().cpu()  #\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can use optymalizer to update parameters based on their gradients\n",
    "# the most simple is stochastic gradient descent (SGD)\n",
    "def torchStep2(x, y, model, optim):\n",
    "    optim.zero_grad()  # clear gradients\n",
    "    y_calc = model(x)  # calculate output of model\n",
    "    loss = mse(y, y_calc)  # calculate loss\n",
    "    loss.backward()  # calculate all gradients\n",
    "    optim.step()  # make a optymalizer step which update parameters\n",
    "    return loss, y_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearLayer(-1.1, 0.2)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "y_calc = y_calc.detach().cpu()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xt[:, 0], yt)\n",
    "line, = plt.plot(xt[:, 0], y_calc, c=\"orange\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    loss, y_calc = torchStep2(xt, yt, model, optim)\n",
    "    y_calc = y_calc.detach().cpu()\n",
    "    line.set_ydata(y_calc)\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "animation.FuncAnimation(fig, animate, np.arange(0, 100), interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image\n",
    "image = np.array(\n",
    "    [\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Complete the below function. It should convolve the input image with the kernel (mask). The kernel is of a 3x3 shape. Additionally, use the bias parameter (modify the result of the convolvution operation). Do not use padding, so the output image should be in size: (input_wight -2) x (input_height -2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Convolution(image, kernel, bias):\n",
    "    img_out = np.zeros((image.shape[0] - 2, image.shape[1] - 2))\n",
    "    ### TODO\n",
    "            \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel (mask) - this is just a simple mean filter\n",
    "kernel = np.ones((3, 3)) / 9\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_out = Convolution(image, kernel, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Find out kernels (masks) which can be used for horizontal and vertical edges detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_horizontal = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_horizontal = Convolution(image, kernel_horizontal, -2)\n",
    "plt.imshow(img_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_vertical = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_vertical = Convolution(image, kernel_vertical, -2)\n",
    "plt.imshow(img_vertical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Complete the below function for calculating ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    ### TODO\n",
    "    ### return 0\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Find values for bias such that output pixels have a value above 0 only if original pixel is a part of the horizontal/vertical line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(relu(Convolution(image, kernel_horizontal, 2)))\n",
    "plt.show()\n",
    "plt.imshow(relu(Convolution(image, kernel_vertical, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "df = pd.read_csv('data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n - number of elements in dataset\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful variables\n",
    "feature_columns = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]\n",
    "target_column = \"variety\"\n",
    "class_number = 3\n",
    "feature_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionaries use to map class name to number\n",
    "name_to_class = {0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}\n",
    "class_to_name = {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion of class name\n",
    "df[target_column] = df[target_column].apply(lambda x: class_to_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take raw numpy data\n",
    "x = df[feature_columns].values\n",
    "y = df[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data to make network input mean value equals 0 and standard deviation 1\n",
    "x = (x - x.mean(0)) / x.std(0)\n",
    "print(x.mean(0))\n",
    "print(x.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conversion numpy array to torch tensor\n",
    "x = torch.FloatTensor(x)\n",
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple neural network with one hidden layer with hidden_nr neuron.\n",
    "# Input_layer can detect some features which are then used by hidden_layer to make predictions.\n",
    "# Between input_layer and hidden_layer: use relu as a nonlinear activation function.\n",
    "# After hidden_layer, there is a sigmoid function because we want the network to return \n",
    "# probabilities for class assignments [0,1]\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_nr, hidden_nr, output_nr):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_nr, hidden_nr)\n",
    "        self.hidden_layer = nn.Linear(hidden_nr, output_nr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy loss equals: $- (y=0) * log(p_0) - (y=1) * log(p_1)  - (y=2) * log(p_2)$ \n",
    "where $p_1, p_2,p_3$ are calculated probabilities for 1,2,3 class assignment; and y=0 means y is classified to class 0, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy means how many samples are classified correctly\n",
    "def Accuracy(y_target, y_calc):\n",
    "    prediction_class = y_calc.max(1)[1]\n",
    "    number_of_correct = (prediction_class == y).float().sum()\n",
    "    return number_of_correct / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Step(x, y, model, optim):\n",
    "    optim.zero_grad()\n",
    "    y_calc = model(x)\n",
    "    loss = loss_func(y_calc, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    acc = Accuracy(y, y_calc)\n",
    "    return loss, y_calc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train function trains model for epoch step and collects metrics (loss and accuracy)\n",
    "def Train(x, y, model, optim, epoch):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i in range(epoch):\n",
    "        loss, y_calc, acc = Step(x, y, model, optim)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(acc)\n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a model and optimalizer\n",
    "hidden_nr = 5\n",
    "model = Net(feature_number, hidden_nr, class_number)\n",
    "optim = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 200\n",
    "losses, accuracies = Train(x, y, model, optim, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task for 5:\n",
    "Choose one of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1) Create a repor on testing the impact of different values for learning rate and number of neurons in hidden layer.\n",
    "\n",
    "    test case 1: \n",
    "    learning rate:[ 1, 0.5, 0.1, 0.01, 0.001]\n",
    "    number of neuron in hidden layer: 10\n",
    "    \n",
    "    test case 2: \n",
    "    number of neuron in hidden layer: [1, 2, 5, 10, 20, 100]\n",
    "    learning rate: 0.1\n",
    "\n",
    "\n",
    "Run every test 10 times with 200 epochs. Plot mean losses and accuracies for each test scenario. Make a table containing scores attained after 200 epochs. These scores should include the best, worst, mean, and standard deviation of lossess and accuracies (you can use pandas describe function). \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) If you have a GPU, you can try to make an image classifier shown in https://course.fast.ai/videos/?lesson=2.\n",
    "Watch the video. You can use the original \"animals\" dataset or prepare your own data set - but this should contain at least 4 different classes. \n",
    "\n",
    "Your task is to create a classifier and show working neural network at the laboratory. Furtermore, make a brief report where you:\n",
    "- describe the dataset: number of samples, some examples, how it was prepared, number of samples in train and validation set, are there images which contains more than one class, batch size.\n",
    "- describe the model: tested models\n",
    "- describe the training process: how the verification process looked like, how many epoch it was run for, how long it took, data cleaning, learning rate finder and so on, plots of losses, and accuracy.\n",
    "- describe the result: confusion matrix, examples of correctly/incorrectly classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
