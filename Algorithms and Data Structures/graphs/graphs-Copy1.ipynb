{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph evaluation report\n",
    "- Academic Year: 2019/20\n",
    "- Faculty of Computing - Artificial Intelligence - Semester 2\n",
    "- Full name and student id: Kacper TrÄ™bacz 145453\n",
    "- Subject: Algorithms and Data Structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise consinst of two parts:\n",
    "- evaluation different graph representations in terms of peformance when searching for an existance of an edge between 2 vertices\n",
    "- determining best representation for topoligical order sorting and evaluate the time needed to perform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint,sample, randrange\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time \n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import copy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "sys.setrecursionlimit(10**9)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ADJACENCY_MATRIX = \"Adjacency Matrix\"\n",
    "INCIDENCE_MATRIX = \"Incidence Matrix\"\n",
    "EDGE_LIST = \"Edge List\"\n",
    "LIST_OF_INCIDENTS = \"List of Incidents\"\n",
    "NUM_OF_RANDOM_POINTS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges count\n",
    "Every graph should have saturation factor of 0.6 in Part 1 and 0.3 for Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_count(n):\n",
    "    return int(n*(n-1)*0.6/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we generate graphs with saturation factor 0.6 and save them to text files. There are 21 graphs of size from 2 to 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_write_to_file(n):\n",
    "    array = np.zeros((n,n), dtype=bool)\n",
    "    n_edges = edges_count(n)\n",
    "#     for i in range(n):\n",
    "#         array[i][i]=True\n",
    "    for i in range(n_edges):\n",
    "        x,y = randrange(n), randrange(n)\n",
    "        while x==y or array[x][y]:\n",
    "            x,y = randrange(n), randrange(n)\n",
    "        array[x][y] = True\n",
    "        array[y][x] = True\n",
    "    os.makedirs(\"data\", exist_ok= True)\n",
    "    np.savetxt(\"data/\"+str(n)+\".txt\", array, fmt=\"%5i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,2003,100):\n",
    "    generate_and_write_to_file(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,203,10):\n",
    "    generate_and_write_to_file(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph representations delaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we delacre functions which convert graphs from text files to a given representation. We also define functions for each reporesentation that check if a given edge exists in graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adjacency_matrix(n,array):\n",
    "    return array\n",
    "\n",
    "def find_edge_adjacency_matrix(array,v1,v2):\n",
    "    return array[v1][v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incidence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_incidence_matrix(n,array):\n",
    "    m=edges_count(n)\n",
    "    new_array = np.zeros((n,m), dtype=bool)\n",
    "    a=0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if array[i][j]:\n",
    "                new_array[i][a] = True\n",
    "                new_array[j][a] = True\n",
    "                a+=1\n",
    "    return new_array\n",
    "\n",
    "def find_edge_incidence_matrix(array, v1, v2):\n",
    "    m=array.shape[0];\n",
    "    for i in range(m):\n",
    "        if(array[v1][i] and array[v2][i]):\n",
    "            return True;\n",
    "    return False\n",
    "#     return np.dot(array[v1], array[v2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_edge_list(n,array):\n",
    "    m=edges_count(n)\n",
    "    new_array = np.zeros((m,2))\n",
    "    a=0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if array[i][j]:\n",
    "                new_array[a][0] = i\n",
    "                new_array[a][1] = j\n",
    "                a+=1\n",
    "    return new_array\n",
    "\n",
    "def find_edge_edge_list(array, v1, v2):\n",
    "    m=array.shape[0];\n",
    "    for i in range(m):\n",
    "        if (array[i][0] == v1 and array[i][1] == v2) or (array[i][0] == v2 and array[i][1] == v1):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_of_incidents(n,array):\n",
    "    m=edges_count(n)\n",
    "    incidents_list = []\n",
    "    for i in range(n):\n",
    "        incidents = []\n",
    "        for j in range(n):\n",
    "            if i !=j and array[i][j] == 1:\n",
    "                incidents.append(j)\n",
    "        incidents_list.append(incidents)\n",
    "    return incidents_list\n",
    "\n",
    "def find_edge_list_of_incidents(array, v1, v2):\n",
    "    return v2 in array[v1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we declare dictionaries that would let us perform tests easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dictionary = {\n",
    "    ADJACENCY_MATRIX : convert_to_adjacency_matrix,\n",
    "    INCIDENCE_MATRIX : convert_to_incidence_matrix,\n",
    "    EDGE_LIST : convert_to_edge_list,\n",
    "    LIST_OF_INCIDENTS : convert_to_list_of_incidents\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dictionary = {\n",
    "    ADJACENCY_MATRIX : find_edge_adjacency_matrix,\n",
    "    INCIDENCE_MATRIX : find_edge_incidence_matrix,\n",
    "    EDGE_LIST : find_edge_edge_list,\n",
    "    LIST_OF_INCIDENTS : find_edge_list_of_incidents\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time measurement and tests functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For graph of each size (n) we perform 100 search operations to see wheather a certain edge exists. We run test of each graph representation on a separate code in order too speed up computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(n,entry):\n",
    "    array = np.loadtxt(\"data/\"+str(n)+\".txt\", dtype=bool)\n",
    "    graph = conversion_dictionary[entry](n,array)\n",
    "    sum_of_times=0\n",
    "    for i in range(NUM_OF_RANDOM_POINTS):\n",
    "        x = randrange(n)\n",
    "        y = randrange(n)\n",
    "        while y == x:\n",
    "            y = randrange(n)\n",
    "        startTime = time.time()\n",
    "        search_dictionary[entry](graph, x, y)\n",
    "        sum_of_times += time.time() - startTime\n",
    "    return sum_of_times/NUM_OF_RANDOM_POINTS\n",
    "\n",
    "def plot_plot(X,Ys,labels,title):\n",
    "    for i in range(len(Ys)):\n",
    "        plt.plot(X,Ys[i],label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Elements')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def perform_test_single_entry(entry, X):\n",
    "    return [measure_time(n, entry) for n in X]\n",
    "    \n",
    "def perform_tests(entries,maximum=2003,jump=100):\n",
    "    X = [i for i in range(2,maximum, jump)]\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    Ys = pool.starmap(perform_test_single_entry,[(entry,X) for entry in entries])\n",
    "    pool.terminate()\n",
    "    plot_plot(X, Ys, entries, \"Edge search time\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we run test for every representaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/kacper/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/kacper/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-13-296c00ac82bd>\", line 25, in perform_test_single_entry\n    return [measure_time(n, entry) for n in X]\n  File \"<ipython-input-13-296c00ac82bd>\", line 25, in <listcomp>\n    return [measure_time(n, entry) for n in X]\n  File \"<ipython-input-13-296c00ac82bd>\", line 11, in measure_time\n    search_dictionary[entry](graph, x, y)\n  File \"<ipython-input-8-bd3b3239d946>\", line 16, in find_edge_incidence_matrix\n    if(array[v1][i] and array[v2][i]):\nIndexError: index 0 is out of bounds for axis 0 with size 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f07ab3bffcaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperform_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mADJACENCY_MATRIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIST_OF_INCIDENTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINCIDENCE_MATRIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEDGE_LIST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m203\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-296c00ac82bd>\u001b[0m in \u001b[0;36mperform_tests\u001b[0;34m(entries, maximum, jump)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjump\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mYs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperform_test_single_entry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mplot_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Edge search time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "perform_tests([ADJACENCY_MATRIX, LIST_OF_INCIDENTS, INCIDENCE_MATRIX, EDGE_LIST],203,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because 'List of Edges' was much slower than the others run next test without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tests([ADJACENCY_MATRIX, LIST_OF_INCIDENTS, INCIDENCE_MATRIX], 1003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, because Incidence Matrix was much slower than the other we run next test with just 'Adjacency Matrix' and 'List of Incidents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tests([ADJACENCY_MATRIX, LIST_OF_INCIDENTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tests([ADJACENCY_MATRIX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we are going to evaluate the efficiency of Topological Order Sort (TOS). We are going to use the 'List of Incidents' representation, because it is the most convinient for this task. It is due to the fact that it structurised in such a way that the TOS algorithm does not need to perform any transformations in order to use this representation. Although it is slower than 'Adjacency Matrix' when searching for an edge, it is more suitable, because if we used 'Adjacency Matrix' we would be creating 'List of Incidents' during operation of the algorithm. It would be a waist of resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we generate 21 graphs of size from 2 to 4002 with saturation factor 0.3 and save them in txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DAG_and_write_to_file(n):\n",
    "    array = np.zeros((n,n), dtype=bool)\n",
    "    n_edges = edges_count(n)\n",
    "    for i in range(n_edges):\n",
    "        x,y = randrange(n), randrange(n)\n",
    "        while x>=y or array[x][y]:\n",
    "            x,y = randrange(n), randrange(n)\n",
    "        array[x][y] = True\n",
    "    os.makedirs(\"data/DAG\", exist_ok= True)\n",
    "    np.savetxt(\"data/DAG/\"+str(n)+\".txt\", array, fmt=\"%5i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,4003,200):\n",
    "    generate_DAG_and_write_to_file(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological order sorting definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_topologically_recursive(ix, list_of_incidents, visited, stack):\n",
    "    visited[ix] = True\n",
    "    for j in list_of_incidents[ix]:\n",
    "        if not visited[j]:\n",
    "            sort_topologically_recursive(j,list_of_incidents, visited, stack)\n",
    "    stack.append(ix)\n",
    "def sort_topologically(n, list_of_incidents):\n",
    "    visited = [False]*n\n",
    "    stack = []\n",
    "    for i in range(n):\n",
    "        if not visited[i]:\n",
    "            sort_topologically_recursive(i, list_of_incidents, visited,stack)\n",
    "    return stack[::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time measurement\n",
    "For every graph of size (n) we measure time of performing TOS on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_2(n):\n",
    "    array = np.loadtxt(\"data/DAG/\"+str(n)+\".txt\", dtype=bool)\n",
    "    list_of_incidents = conversion_dictionary[LIST_OF_INCIDENTS](n,array)\n",
    "    startTime = time.time()\n",
    "    order = sort_topologically(n, list_of_incidents)\n",
    "    processTime = time.time() - startTime\n",
    "    return processTime\n",
    "\n",
    "def perform_test():\n",
    "    X = [i for i in range(2,4003, 200)]\n",
    "    Ys = [[measure_time_2(n) for n in X]]\n",
    "    plot_plot(X, Ys, [\"Topological sort\"], \"Topological sort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "We could clearly see hugde differences between each of graphs representations. They were so big that we needed to remove one of representations each time in order to compare others. For 2000 elements Edge list was 1000x slower than Incidence Matrix, which was slower 500x slower than 'List of Incidents'.\n",
    "\n",
    "The best one was Adjacency Matrix which had constant search time O(n). List of incidents was slower because on average it woud search through n nodes in list and then through (n-1)*0.6/2 edges so it is O(n).\n",
    "\n",
    "Almost the worst one was Incidence Matrix which needed to perform a dot product operation on 2 arrays of size n(n-1)*0.6/2 edges so it complexity is O(n^2) which is same as Edge List. the key difference is that 'Incidence Matrix' is stored in an array and 'Edge List' is stored in list. Thats why it is so slow.\n",
    "\n",
    "## Part2\n",
    "\n",
    "Theoretical complexity of topological sorting algorithm is O(E + V), where V is number of verticies (n in our case) and E is number of edges (n(n-1)*0.3/2 in our case) which gives O(n^2) complexity in our case. It is clearly visible in our graph. It is thanks to representation that we chose. As I wrote earlier this representation is better than the others, because it is straightforward to use by our algorithm. Every other represention would require us to do some transformations which would take additional time. In a setting where we would have almost none edges. Than edge list could be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
